{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Adversarial AutoEncoder\n",
    "Implementation vanilla (no CNN) Unconditioned Adversarial AutoEncoder. This architecture forces the latent space of an autoencoder to follow a particular distribution, in a way more efficient than Variational AutoEncoders.\n",
    "\n",
    "In other words it makes a simple autoencoder become a generative model.\n",
    "\n",
    "#### What you can do\n",
    "* Semi-supervised classification\n",
    "* Generative Modeling (Unconditioned and Conditioned)\n",
    "* Dimensionaliry Reduction\n",
    "* Clustering\n",
    "\n",
    "#### Losses\n",
    "* Reconstruction Loss\n",
    "* Discriminator Loss\n",
    "* Generator (encoder) Loss\n",
    "\n",
    "The adversarial training criterion forces the autoencoder latent follow any particular distribution.\n",
    "\n",
    "#### References\n",
    "* [Paper](https://arxiv.org/pdf/1511.05644.pdf)\n",
    "* https://github.com/neale/Adversarial-Autoencoder\n",
    "* https://github.com/bfarzin/pytorch_aae\n",
    "* https://blog.paperspace.com/adversarial-autoencoders-with-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Pytorch version: 1.2.0\n"
     ]
    }
   ],
   "source": [
    "import mnist_data_pytorch as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "print('Pytorch version:', torch.__version__)\n",
    "# Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "!rm -rf ./runs\n",
    "writer = SummaryWriter('./runs/train')\n",
    "\n",
    "# Metaparameters\n",
    "num_epochs = 30\n",
    "latent_size = 100\n",
    "gen_lr = 0.0001\n",
    "reg_lr = 0.00005\n",
    "EPS = 1e-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Encoder/Decoder/Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):  \n",
    "    def __init__(self, X_dim, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lin1 = nn.Linear(X_dim, 1000)\n",
    "        self.lin2 = nn.Linear(1000, 1000)\n",
    "        self.latent = nn.Linear(1000, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        z = self.latent(x)\n",
    "        return z\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):  \n",
    "    def __init__(self, X_dim, z_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim, 1000)\n",
    "        self.lin2 = nn.Linear(1000, 1000)\n",
    "        self.lin3 = nn.Linear(1000, X_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "\n",
    "class Discriminator(nn.Module):  \n",
    "    def __init__(self, z_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim, 500)\n",
    "        self.lin2 = nn.Linear(500, 500)\n",
    "        self.lin3 = nn.Linear(500, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        return torch.sigmoid(self.lin3(x)) \n",
    "\n",
    "\n",
    "# Initialize Networks\n",
    "encoder = Encoder(784, latent_size).to(device)\n",
    "decoder = Decoder(784, latent_size).to(device)\n",
    "discriminator = Discriminator(latent_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_encoder = torch.optim.Adam(encoder.parameters(), lr=gen_lr)\n",
    "optim_decoder = torch.optim.Adam(decoder.parameters(), lr=gen_lr)\n",
    "#regularizing optimizers\n",
    "optim_encoder_generator = torch.optim.Adam(encoder.parameters(), lr=reg_lr)\n",
    "optim_discriminator = torch.optim.Adam(discriminator.parameters(), lr=reg_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:16<00:00,  2.56s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    running_loss_discriminator = 0.0\n",
    "    running_loss_generator = 0.0\n",
    "    running_loss_reconstruction = 0.0\n",
    "    # Iterate over the data\n",
    "    for idx_sample, (inputs, _) in enumerate(data.dataloaders['train']):\n",
    "        inputs = inputs.to(device)\n",
    "        inputs = torch.flatten(inputs, start_dim=1, end_dim=-1)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optim_encoder.zero_grad()\n",
    "        optim_decoder.zero_grad()\n",
    "        optim_discriminator.zero_grad()\n",
    "        \n",
    "        z_sample = encoder(inputs)\n",
    "        inputs_reconstruct = decoder(z_sample) #decode to X reconstruction\n",
    "        reconstruct_loss = F.binary_cross_entropy(inputs_reconstruct + EPS, inputs + EPS)\n",
    "        \n",
    "        # Backprop from reconstruction loss\n",
    "        reconstruct_loss.backward()\n",
    "        # Optimizer Encoder/Decoder\n",
    "        optim_encoder.step()\n",
    "        optim_decoder.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss_reconstruction += reconstruct_loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Discriminator\n",
    "        ## true prior is random normal (randn)\n",
    "        ## this is constraining the Z-projection to be normal!\n",
    "        encoder.eval()\n",
    "        batch_size = inputs.size()[0]\n",
    "        z_real_gauss = (torch.randn(batch_size, latent_size) * 1.).to(device)\n",
    "        D_real_gauss = discriminator(z_real_gauss)\n",
    "\n",
    "        # Fake images come from encoder(generator)\n",
    "        z_fake_gauss = encoder(inputs)\n",
    "        D_fake_gauss = discriminator(z_fake_gauss)\n",
    "\n",
    "        D_loss = -torch.mean(torch.log(D_real_gauss + EPS) + torch.log(1 - D_fake_gauss + EPS))\n",
    "\n",
    "        D_loss.backward()\n",
    "        optim_discriminator.step()\n",
    "        # Update statistics\n",
    "        running_loss_discriminator += D_loss.item() * inputs.size(0)\n",
    "\n",
    "        # Generator\n",
    "        encoder.train()\n",
    "        z_fake_gauss = encoder(inputs)\n",
    "        D_fake_gauss = discriminator(z_fake_gauss)\n",
    "\n",
    "        G_loss = -torch.mean(torch.log(D_fake_gauss + EPS))\n",
    "\n",
    "        G_loss.backward()\n",
    "        optim_encoder_generator.step()   \n",
    "        # Update statistics\n",
    "        running_loss_generator += G_loss.item() * inputs.size(0)\n",
    "    \n",
    "    # Epoch ends\n",
    "    epoch_loss_generator = running_loss_generator / len(data.dataloaders['train'].dataset)\n",
    "    epoch_loss_discriminator = running_loss_discriminator / len(data.dataloaders['train'].dataset)\n",
    "    epoch_loss_reconstruction = running_loss_reconstruction / len(data.dataloaders['train'].dataset)\n",
    "    \n",
    "    # Send results to tensorboard\n",
    "    writer.add_scalar('train/loss_generator', epoch_loss_generator, epoch)\n",
    "    writer.add_scalar('train/loss_discriminator', epoch_loss_discriminator, epoch)\n",
    "    writer.add_scalar('train/reconstruction', epoch_loss_reconstruction, epoch)\n",
    "    \n",
    "    # Send images to tensorboar\n",
    "    writer.add_images('train/decoder_images', inputs_reconstruct.view(inputs.size(0),1,28,28), epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Samples (Unconditioned)\n",
    "Observe that the generated samples are somehow a mix of all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(num_idx=0):\n",
    "    decoder.eval()\n",
    "    z_real_gauss = (torch.randn(1, latent_size) * 5.).to(device)\n",
    "    with torch.no_grad(): \n",
    "        generated_sample = decoder(z_real_gauss)\n",
    "\n",
    "    plt.imshow(generated_sample.view(28,28).cpu().numpy())\n",
    "    plt.title('Generated sample')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7265b6b8a2441ca859d943ab6132f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='num_idx'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(generate_sample, num_idx=widgets.IntSlider(min=0, max=100, step=1, value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAASfElEQVR4nO3dfZRcdX3H8fdnH5KQJ0hICJFQngwKaI2yAhW1eKAW0GNQEaGVBkRDWzmVI22h2FNii5VaFemTGBXFB1BaQaiHWtIcFDkUZKEUgikQMJKQkAAByQMkm91v/7g3OCw7d3Zn7jxsfp/XOXN25n7v3fnO3fnMnbl37v4UEZjZ7q+r3Q2YWWs47GaJcNjNEuGwmyXCYTdLhMNulgiH3cZM0lmSbm93H0UkrZZ0Qrv76CQOe0kknS7pLklbJW3Mr/+xJLW7t+Ek/VjSR9rdh7WWw14CSRcAVwB/D+wLzAH+EDgWmNDiXnpaeX82jkSELw1cgD2BrcD7a8w3Efgc8DiwAbgS2COvHQesBS4ANgLrgbPHuOyFwJPAt4AZwA+Bp4Bn8+vz8vk/DQwCLwJbgH/Kp78WWAZsAh4CTqu4/72Bm4DngZ8BfwPcXuVxTgK+DTwDPAfcDczJa2cDK4HNwGPAuRXL7Xocf16xDk4BTgYezvu6uGL+JcC/Ad/Lf9+9wBsq6quBE/LrXcBFwKN5X9cBM9v93Gn5c7XdDYz3C3AisBPoqTHfF/PAzASmAf8OfCavHZf/jr8GevMn+DZgxhiW/bv8RWGPPJzvBybn8/8r8IOKXn4MfKTi9hRgTR7GHuBNwNPAEXn9u3lApgCvA54oCPu5eX+TgW7gSGB6XnsXcAgg4Lfzx/imYY/jr/J18FGyF6tr8sdwBNkL1MH5/EuAAeDUfP4/BX4B9Ob1yrCfD9wJzMvX0ZeBa9v93Gn5c7XdDYz3C/Ah4Mlh0+4g26q9ALw9f3JvBQ6pmOe3gF/k14/L5+2pqG8EjhnlsjuASQU9LgCerbg9POwfBH46bJkvA5fkgR0AXltR+9uCsH84f/y/OYp19wPg48PWQXd+exoQwNEV898DnJJfXwLcWVHrIns38Lb8dmXYVwLHV8w7N39MhS/Qu9vFn+8a9wwwS1JPROwEiIi3AEhaS/YknE22pbunYn+dyIL00u/ZtXxuGzB1lMs+FREvvlSUJgOXk73rmJFPniapOyIGR3gMBwBHS3quYloP2UeC2fn1NRW1X468KiBfZn/gu5L2IntL/8mIGJB0EtkLyKFk62Uy8MCwdbCrvxfynxsq6i+QrZNdXuopIoby9f2qKo/vBklDFdMGyfatPFHwWHYr3kHXuP8GtgMLC+Z5muyJekRE7JVf9oyIqQXLjGXZ4acuXgC8hmyrOJ3s3QVkLxIjzb8G+EnF798rIqZGxB+RvZXeSRbgXX6jWrMRMRARn4qIw4G3AO8G/kDSROD7ZPse5kTEXsDNFT3V46WeJHWRvU1fN8J8a4CThj2+SRGRTNDBYW9YRDwHfAr4F0mnSpoqqUvSArLPuETEEPAV4HJJ+wBI2k/S747i99ez7DSyF4jnJM0k25pW2gAcXHH7h8Chks6U1Jtf3izpsHxLez2wRNJkSYcDi6rdsaR3SHq9pG6yHXoDZFvRCWSfl58CduZb+XfWevw1HCnpffkRiPPJXnTvHGG+K4FPSzog73G2pKIX592Sw16CiPgs8Al+vSd5A9ln3gvJPr+SX18F3CnpeeC/yLa+ozHWZb9ItqPuabIn/4+G1a8ATpX0rKR/iIjNZME7nWzL+CS/3uEHcB7Z2+cngW8AXy+4733J9pI/T/ZZ+SfAt/P7+BOyHX3PAr9HttOxETeS7W94FjgTeF9EDIww3xX5fd0iaTPZOjm6wfsed5TvsDAbVyQtAV4dER9qdy/jhbfsZolw2M0S4bfxZonwlt0sES39Us0ETYxJ2dEoM2uCF9nKjtg+4ncXGgq7pBPJDmt0A1+NiMuK5p/EFI7W8Y3cpZkVuCuWV63V/TY+/9LEPwMnAYcDZ+RfuDCzDtTIZ/ajgFUR8VhE7CA7Myq5byWZjReNhH0/Xn5yxNp82stIWiypX1L/ANsbuDsza0QjYR9pJ8ArjuNFxNKI6IuIvt6Xvn1pZq3WSNjX8vIzoaqdcWRmHaCRsN8NzJd0kKQJZCdRNHpig5k1Sd2H3iJip6TzgP8kO/R2VUQ8WFpnZlaqho6zR8TNZP+AwMw6nL8ua5YIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiWhoFFcb/7qmTSusa86swvrgrOLlu1c9UX3ZTc8VLsvQYHHdxqShsEtaDWwGBoGdEdFXRlNmVr4ytuzviIinS/g9ZtZE/sxulohGwx7ALZLukbR4pBkkLZbUL6l/gO0N3p2Z1avRt/HHRsQ6SfsAyyT9X0TcVjlDRCwFlgJM18xo8P7MrE4NbdkjYl3+cyNwA3BUGU2ZWfnqDrukKZKm7boOvBNYUVZjZlauRt7GzwFukLTr91wTET8qpSsbk67Jk6vWtP+rCpd983UrC+sX7r28sD5R9T+F1g9uK6y/5zN/VliffeWdxXcQ/tRYqe6/VEQ8BryhxF7MrIl86M0sEQ67WSIcdrNEOOxmiXDYzRLhU1zHg+zwZlVde06vWtv6jzsLl/3LWfcX1ns1obDeiHk9Uwvrt1z8ucL6wmcuKKxPva7GobnEeMtulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCx9nHAxW/Jg/NmVm19sX5Xy9ctlcT62qpFaZ1FR/j3+OpHS3qZPfgLbtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulggfZx8PYqiwvOGYPavWZnUP1PjlnXuc/YYt+xTWe35afC6+/5H0y3nLbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwsfZx4Ma57P/6tDqR5RX7Ni7cNm53S8U1rtr3HczXfr1Mwrr++28o0Wd7B5q/iUlXSVpo6QVFdNmSlom6ZH854zmtmlmjRrNy/Y3gBOHTbsIWB4R84Hl+W0z62A1wx4RtwGbhk1eCFydX78aOKXkvsysZPV+IJsTEesB8p9Vv8QsabGkfkn9A2yv8+7MrFFN3/sSEUsjoi8i+no7+KQLs91dvWHfIGkuQP5zY3ktmVkz1Bv2m4BF+fVFwI3ltGNmzVLzOLuka4HjgFmS1gKXAJcB10k6B3gc+EAzm0xdz5zZhfV9Dnuqam2Q4rHd23kcfSAGC+vzlv2qsO7z1cemZtgjoto3G44vuRczayJ/XdYsEQ67WSIcdrNEOOxmiXDYzRLhU1zHgcF9i09TPWj6uqq1g3uGn9Yw3OQ6OirHlqHir093Pbq2sF584M6G85bdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEj7OPA11rniys3/cfh1WtdX/0h2W3U5o7ts8srA9tLf431zY23rKbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZonwcfZxYHDTc4X1ebduq1p77KziY9mH9DR3yObBGKpaO//6swuXPXjnnQ3dt72ct+xmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSJ8nH030PPzX1at3bX1kMJl3zrp3sL6VE2qq6ddlr8wsWrt1dcUD8k8FB6UuUw1t+ySrpK0UdKKimlLJD0h6b78cnJz2zSzRo3mbfw3gBNHmH55RCzILzeX25aZla1m2CPiNqDWGEJm1uEa2UF3nqT787f5M6rNJGmxpH5J/QMUj+1lZs1Tb9i/BBwCLADWA5+vNmNELI2Ivojo66X6zhoza666wh4RGyJiMCKGgK8AR5XblpmVra6wS5pbcfO9wIpq85pZZ6h5nF3StcBxwCxJa4FLgOMkLQACWA2c28QerYYX31z9WPq3lr2mcNkPfeBnhfUudhTWu6XC+kPbD6hefHRN4bJWrpphj4gzRpj8tSb0YmZN5K/LmiXCYTdLhMNulgiH3SwRDrtZInyKayeocfiqa8rkwvoeq56uWut+29yqNYBHBvYurM/t3lxYr2Xb0ISqNdV43FYub9nNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0T4OHsr1DqOPrn4OHrXXnsW1n/+F7Or1k5a8D+Fy76m95nC+uSuqYX1Wj4244GqtVv63l64bM+txf/mGv+r6THxlt0sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4SPs5dAPcWrUUfML6xvOXh6cf2s4qGNrzj8O1Vr75q8pXDZbjV2HL2WqV3Vh3xe/eGhwmVffWvZ3aTNW3azRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBGjGbJ5f+CbwL7AELA0Iq6QNBP4HnAg2bDNp0XEs81rtXN1zZhRWF/1wb0K6189/UuF9aMnDhTWJ6q3oNq5r+dd66ofgwd8vnrJRvNM2AlcEBGHAccAH5N0OHARsDwi5gPL89tm1qFqhj0i1kfEvfn1zcBKYD9gIXB1PtvVwCnNatLMGjem93iSDgTeCNwFzImI9ZC9IAD7lN2cmZVn1GGXNBX4PnB+RDw/huUWS+qX1D/A9np6NLMSjCrsknrJgv6diLg+n7xB0ty8PhfYONKyEbE0Ivoioq+XiWX0bGZ1qBl2ZUNtfg1YGRFfqCjdBCzKry8Cbiy/PTMry2hOcT0WOBN4QNJ9+bSLgcuA6ySdAzwOfKA5LXa+oXnFuysuef91hfXGDq11tsGofhrr/EsfLF627GYSVzPsEXE7UO0fnx9fbjtm1iyd+40LMyuVw26WCIfdLBEOu1kiHHazRDjsZonwv5IugR76RWH98w+dUFg/7chrymynpYqOowO8+9C3Va0NbR31t66tBN6ymyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJ8HH2Egxt21ZYn73w4cL6e17/+4X1U7/348L6+6Y+VrU2vWDIZIAXYkdh/agrP1FY3//SOwrrsLVG3VrFW3azRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBGKFg6LO10z42j5v0+bNctdsZznY9OI//rdW3azRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBE1wy5pf0m3Slop6UFJH8+nL5H0hKT78svJzW/XzOo1mn9esRO4ICLulTQNuEfSsrx2eUR8rnntmVlZaoY9ItYD6/PrmyWtBPZrdmNmVq4xfWaXdCDwRuCufNJ5ku6XdJWkGVWWWSypX1L/ANsbatbM6jfqsEuaCnwfOD8inge+BBwCLCDb8n9+pOUiYmlE9EVEXy8TS2jZzOoxqrBL6iUL+nci4nqAiNgQEYMRMQR8BTiqeW2aWaNGszdewNeAlRHxhYrpcytmey+wovz2zKwso9kbfyxwJvCApPvyaRcDZ0haAASwGji3KR2aWSlGszf+dmCk82NvLr8dM2sWf4POLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJaKlQzZLegr4ZcWkWcDTLWtgbDq1t07tC9xbvcrs7YCImD1SoaVhf8WdS/0R0de2Bgp0am+d2he4t3q1qje/jTdLhMNuloh2h31pm++/SKf21ql9gXurV0t6a+tndjNrnXZv2c2sRRx2s0S0JeySTpT0kKRVki5qRw/VSFot6YF8GOr+NvdylaSNklZUTJspaZmkR/KfI46x16beOmIY74Jhxtu67to9/HnLP7NL6gYeBn4HWAvcDZwRET9vaSNVSFoN9EVE27+AIentwBbgmxHxunzaZ4FNEXFZ/kI5IyIu7JDelgBb2j2Mdz5a0dzKYcaBU4CzaOO6K+jrNFqw3tqxZT8KWBURj0XEDuC7wMI29NHxIuI2YNOwyQuBq/PrV5M9WVquSm8dISLWR8S9+fXNwK5hxtu67gr6aol2hH0/YE3F7bV01njvAdwi6R5Ji9vdzAjmRMR6yJ48wD5t7me4msN4t9KwYcY7Zt3VM/x5o9oR9pGGkuqk43/HRsSbgJOAj+VvV210RjWMd6uMMMx4R6h3+PNGtSPsa4H9K27PA9a1oY8RRcS6/OdG4AY6byjqDbtG0M1/bmxzPy/ppGG8RxpmnA5Yd+0c/rwdYb8bmC/pIEkTgNOBm9rQxytImpLvOEHSFOCddN5Q1DcBi/Lri4Ab29jLy3TKMN7Vhhmnzeuu7cOfR0TLL8DJZHvkHwU+2Y4eqvR1MPC/+eXBdvcGXEv2tm6A7B3ROcDewHLgkfznzA7q7VvAA8D9ZMGa26be3kr20fB+4L78cnK7111BXy1Zb/66rFki/A06s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwR/w/gb46rmJal8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
