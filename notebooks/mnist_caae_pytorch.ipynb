{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Conditional Adversarial AutoEncoder\n",
    "Implementation of vanilla (no CNN) Conditional Adversarial AutoEncoder. This architecture forces the latent space of an autoencoder to follow a particular distribution, in a way more efficient than Variational AutoEncoders.\n",
    "\n",
    "In other words it makes a simple autoencoder become a generative model.\n",
    "\n",
    "The main difference is that we will inject (concatenate) our label information (one-hot) into the latent space on the decoder, no change in loss or anything else.\n",
    "\n",
    "The main use of this architecture is to augment datasets.\n",
    "\n",
    "#### Losses\n",
    "* Reconstruction Loss\n",
    "* Discriminator Loss\n",
    "* Generator (encoder) Loss\n",
    "\n",
    "The adversarial training criterion forces the autoencoder latent follow any particular distribution.\n",
    "\n",
    "#### References\n",
    "* [Paper](https://arxiv.org/pdf/1511.05644.pdf)\n",
    "* https://github.com/neale/Adversarial-Autoencoder\n",
    "* https://github.com/bfarzin/pytorch_aae\n",
    "* https://blog.paperspace.com/adversarial-autoencoders-with-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Pytorch version: 1.2.0\n"
     ]
    }
   ],
   "source": [
    "import mnist_data_pytorch as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "print('Pytorch version:', torch.__version__)\n",
    "# Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "!rm -rf ./runs\n",
    "writer = SummaryWriter('./runs/train')\n",
    "\n",
    "# Metaparameters\n",
    "num_epochs = 30\n",
    "num_classes = 10\n",
    "latent_size = 100\n",
    "gen_lr = 0.0001\n",
    "reg_lr = 0.00005\n",
    "EPS = 1e-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to convert labels to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: one-hot tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "9: one-hot tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "def one_hot(labels, num_classes=10):\n",
    "    \"\"\"\n",
    "    Convert labels to one_hot_encoding\n",
    "    \"\"\"\n",
    "    # Convert to One Hot Encoding\n",
    "    y = torch.eye(num_classes)\n",
    "    return y[labels]\n",
    "\n",
    "print('1: one-hot', one_hot(1))\n",
    "print('9: one-hot', one_hot(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Encoder/Decoder/Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):  \n",
    "    def __init__(self, X_dim, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lin1 = nn.Linear(X_dim, 1000)\n",
    "        self.lin2 = nn.Linear(1000, 1000)\n",
    "        self.latent = nn.Linear(1000, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        z = self.latent(x)\n",
    "        return z\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):  \n",
    "    def __init__(self, X_dim, z_dim, num_classes=10):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim + num_classes, 1000)\n",
    "        self.lin2 = nn.Linear(1000, 1000)\n",
    "        self.lin3 = nn.Linear(1000, X_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "\n",
    "class Discriminator(nn.Module):  \n",
    "    def __init__(self, z_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim, 1000)\n",
    "        self.lin2 = nn.Linear(1000, 1000)\n",
    "        self.lin3 = nn.Linear(1000, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        return torch.sigmoid(self.lin3(x)) \n",
    "\n",
    "\n",
    "# Initialize Networks\n",
    "encoder = Encoder(784, latent_size).to(device)\n",
    "decoder = Decoder(784, latent_size).to(device)\n",
    "discriminator = Discriminator(latent_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_encoder = torch.optim.Adam(encoder.parameters(), lr=gen_lr)\n",
    "optim_decoder = torch.optim.Adam(decoder.parameters(), lr=gen_lr)\n",
    "#regularizing optimizers\n",
    "optim_encoder_generator = torch.optim.Adam(encoder.parameters(), lr=reg_lr)\n",
    "optim_discriminator = torch.optim.Adam(discriminator.parameters(), lr=reg_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:24<00:00,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    running_loss_discriminator = 0.0\n",
    "    running_loss_generator = 0.0\n",
    "    running_loss_reconstruction = 0.0\n",
    "    # Iterate over the data\n",
    "    for idx_sample, (inputs, labels) in enumerate(data.dataloaders['train']):\n",
    "        inputs = inputs.to(device)\n",
    "        inputs = torch.flatten(inputs, start_dim=1, end_dim=-1)\n",
    "        inputs = inputs * 0.3081 + 0.1307\n",
    "        labels = labels.to(device)\n",
    "        # Convert y to one-hot and send to GPU\n",
    "        y = one_hot(labels)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optim_encoder.zero_grad()\n",
    "        optim_decoder.zero_grad()\n",
    "        optim_discriminator.zero_grad()\n",
    "        \n",
    "        # Concatenate label (one-hot) with latent\n",
    "        z_sample = encoder(inputs)\n",
    "        z_sample = torch.cat((y, z_sample), 1)\n",
    "        \n",
    "        # Reconstruct X\n",
    "        inputs_reconstruct = decoder(z_sample)\n",
    "        reconstruct_loss = F.binary_cross_entropy(inputs_reconstruct + EPS, inputs + EPS)\n",
    "        \n",
    "        # Backprop from reconstruction loss\n",
    "        reconstruct_loss.backward()\n",
    "        # Optimizer Encoder/Decoder\n",
    "        optim_encoder.step()\n",
    "        optim_decoder.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss_reconstruction += reconstruct_loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Discriminator\n",
    "        ## true prior is random normal (randn)\n",
    "        ## this is constraining the Z-projection to be normal!\n",
    "        encoder.eval()\n",
    "        batch_size = inputs.size()[0]\n",
    "        z_real_gauss = (torch.randn(batch_size, latent_size) * 5.).to(device)\n",
    "        D_real_gauss = discriminator(z_real_gauss)\n",
    "\n",
    "        # Fake images come from encoder(generator)\n",
    "        z_fake_gauss = encoder(inputs)\n",
    "        D_fake_gauss = discriminator(z_fake_gauss)\n",
    "\n",
    "        D_loss = -torch.mean(torch.log(D_real_gauss + EPS) + torch.log(1 - D_fake_gauss + EPS))\n",
    "\n",
    "        D_loss.backward()\n",
    "        optim_discriminator.step()\n",
    "        # Update statistics\n",
    "        running_loss_discriminator += D_loss.item() * inputs.size(0)\n",
    "\n",
    "        # Generator\n",
    "        encoder.train()\n",
    "        z_fake_gauss = encoder(inputs)\n",
    "        #z_fake_gauss = torch.cat((y, z_fake_gauss), 1)\n",
    "        D_fake_gauss = discriminator(z_fake_gauss)\n",
    "\n",
    "        G_loss = -torch.mean(torch.log(D_fake_gauss + EPS))\n",
    "\n",
    "        G_loss.backward()\n",
    "        optim_encoder_generator.step()   \n",
    "        # Update statistics\n",
    "        running_loss_generator += G_loss.item() * inputs.size(0)\n",
    "    \n",
    "    # Epoch ends\n",
    "    epoch_loss_generator = running_loss_generator / len(data.dataloaders['train'].dataset)\n",
    "    epoch_loss_discriminator = running_loss_discriminator / len(data.dataloaders['train'].dataset)\n",
    "    epoch_loss_reconstruction = running_loss_reconstruction / len(data.dataloaders['train'].dataset)\n",
    "    \n",
    "    # Send results to tensorboard\n",
    "    writer.add_scalar('train/loss_generator', epoch_loss_generator, epoch)\n",
    "    writer.add_scalar('train/loss_discriminator', epoch_loss_discriminator, epoch)\n",
    "    writer.add_scalar('train/reconstruction', epoch_loss_reconstruction, epoch)\n",
    "    \n",
    "    # Send images to tensorboard\n",
    "    writer.add_images('train/decoder_images', inputs_reconstruct.view(inputs.size(0),1,28,28), epoch)\n",
    "    \n",
    "    # Send latent to tensorboard\n",
    "    writer.add_histogram('train/latent', z_sample, epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Samples (Unconditioned)\n",
    "Observe that the generated samples are somehow a mix of all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(num_idx=0, category=0):\n",
    "    decoder.eval()\n",
    "    one_hot_category = one_hot([category]).to(device)\n",
    "    print(one_hot_category.shape)\n",
    "    z_real_gauss = (torch.randn(1, latent_size) * .5).to(device)\n",
    "    z_real_gauss = torch.cat((one_hot_category, z_real_gauss), 1)\n",
    "    with torch.no_grad(): \n",
    "        generated_sample = decoder(z_real_gauss)\n",
    "\n",
    "    plt.imshow(generated_sample.view(28,28).cpu().numpy())\n",
    "    plt.title('Generated sample')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27d9526312b4643bb5a596a4ac30a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='num_idx'), Dropdown(description='category', options=(0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(generate_sample, num_idx=widgets.IntSlider(min=0, max=100, step=1, value=0), category = [x for x in range(10)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sample(0,7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
