{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pix2Pix\n",
    "\n",
    "#### References\n",
    "* [Datasets](https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/)\n",
    "* [Code](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/pix2pix/pix2pix.py)\n",
    "* [Another Code](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)\n",
    "* [Paper](https://arxiv.org/pdf/1611.07004.pdf)\n",
    "* [Confluece page](https://machinereinforcedbook.atlassian.net/wiki/spaces/ML/pages/22052990/Pix2Pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Number of GPUs Available: 8\n",
      "Pytorch version: 1.2.0\n",
      "Patch size: (1, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models import utils_unet\n",
    "from dataset_utils.img_folder_dataset import ImageDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "num_gpu = torch.cuda.device_count()\n",
    "#num_gpu = 8\n",
    "print('Number of GPUs Available:', num_gpu)\n",
    "print('Pytorch version:', torch.__version__)\n",
    "\n",
    "# Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "!rm -rf ./runs\n",
    "writer = SummaryWriter('./runs/train')\n",
    "\n",
    "# Metaparameters\n",
    "learning_rate = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "img_height = img_width = 256\n",
    "dataset_name = 'maps'\n",
    "batch_size = 5\n",
    "num_epochs = 200\n",
    "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
    "lambda_pixel = 100\n",
    "\n",
    "# Calculate output of image discriminator (PatchGAN)\n",
    "patch = (1, img_height // 2 ** 4, img_width // 2 ** 4)\n",
    "print('Patch size:', patch)\n",
    "\n",
    "invert_targets = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_ = [\n",
    "    transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    ImageDataset(\"../data/%s\" % dataset_name, transforms_=transforms_),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=10,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    ImageDataset(\"../data/%s\" % dataset_name, transforms_=transforms_, mode=\"val\"),\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare Generator and Discriminator Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
      "    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GeneratorUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(GeneratorUNet, self).__init__()\n",
    "\n",
    "        self.down1 = utils_unet.UNetDown(in_channels, 64, normalize=False)\n",
    "        self.down2 = utils_unet.UNetDown(64, 128)\n",
    "        self.down3 = utils_unet.UNetDown(128, 256)\n",
    "        self.down4 = utils_unet.UNetDown(256, 512, dropout=0.5)\n",
    "        self.down5 = utils_unet.UNetDown(512, 512, dropout=0.5)\n",
    "        self.down6 = utils_unet.UNetDown(512, 512, dropout=0.5)\n",
    "        self.down7 = utils_unet.UNetDown(512, 512, dropout=0.5)\n",
    "        self.down8 = utils_unet.UNetDown(512, 512, normalize=False, dropout=0.5)\n",
    "\n",
    "        self.up1 = utils_unet.UNetUp(512, 512, dropout=0.5)\n",
    "        self.up2 = utils_unet.UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up3 = utils_unet.UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up4 = utils_unet.UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up5 = utils_unet.UNetUp(1024, 256)\n",
    "        self.up6 = utils_unet.UNetUp(512, 128)\n",
    "        self.up7 = utils_unet.UNetUp(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, 4, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # U-Net generator with skip connections from encoder to decoder\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "        u1 = self.up1(d8, d7)\n",
    "        u2 = self.up2(u1, d6)\n",
    "        u3 = self.up3(u2, d5)\n",
    "        u4 = self.up4(u3, d4)\n",
    "        u5 = self.up5(u4, d3)\n",
    "        u6 = self.up6(u5, d2)\n",
    "        u7 = self.up7(u6, d1)\n",
    "        return self.final(u7)\n",
    "    \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels * 2, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        # Concatenate image and condition image by channels to produce input\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)\n",
    "\n",
    "G = GeneratorUNet()\n",
    "writer.add_graph(G, torch.ones((1,3,256,256)))\n",
    "G = G.to(device)\n",
    "D = Discriminator().to(device)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_pixelwise = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=learning_rate, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr=learning_rate, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 6/200 [02:52<1:33:02, 28.78s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    running_loss_G = 0.0\n",
    "    running_loss_D = 0.0\n",
    "    running_pixelwise_loss = 0.0\n",
    "    # Iterate over the training data\n",
    "    for idx_sample, batch in enumerate(dataloader_train):\n",
    "        if invert_targets:\n",
    "            real_A = batch[\"B\"].to(device)\n",
    "            real_B = batch[\"A\"].to(device)\n",
    "        else:\n",
    "            real_A = batch[\"A\"].to(device)\n",
    "            real_B = batch[\"B\"].to(device)\n",
    "        batch_size = real_B.size()[0]\n",
    "        \n",
    "        # Adversarial ground truths (you can do soft-label here....)\n",
    "        # Remember that our discriminator outputs a grid of patches\n",
    "        valid = torch.ones(batch_size, *patch).to(device)\n",
    "        fake = torch.zeros(batch_size, *patch).to(device)\n",
    "    \n",
    "        # Train Generators\n",
    "        optimizer_G.zero_grad()\n",
    "        # GAN loss\n",
    "        fake_B = G(real_A)\n",
    "        pred_fake = D(fake_B, real_A)\n",
    "        \n",
    "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "        \n",
    "        # Pixel-wise loss\n",
    "        loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
    "        \n",
    "        # Total loss\n",
    "        loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        # Real loss\n",
    "        pred_real = D(real_B, real_A)\n",
    "        loss_real = criterion_GAN(pred_real, valid)\n",
    "        # Fake loss\n",
    "        pred_fake = D(fake_B.detach(), real_A)\n",
    "        loss_fake = criterion_GAN(pred_fake, fake)\n",
    "        # Total loss\n",
    "        loss_D = 0.5 * (loss_real + loss_fake)\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss_G += loss_G.item() * batch_size\n",
    "        # Update statistics\n",
    "        running_loss_D += loss_D.item() * batch_size\n",
    "    \n",
    "    # Epoch ends\n",
    "    epoch_loss_generator = running_loss_G / len(dataloader_train.dataset)\n",
    "    epoch_loss_discriminator = running_loss_D / len(dataloader_train.dataset)\n",
    "    \n",
    "    # Send results to tensorboard\n",
    "    writer.add_scalar('train/loss_generator', epoch_loss_generator, epoch)\n",
    "    writer.add_scalar('train/loss_discriminator', epoch_loss_discriminator, epoch)\n",
    "    \n",
    "    # Send images to tensorboard\n",
    "    writer.add_images('train/real_A', real_A, epoch)\n",
    "    writer.add_images('train/real_B', real_B, epoch)\n",
    "    writer.add_images('train/G', fake_B, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
